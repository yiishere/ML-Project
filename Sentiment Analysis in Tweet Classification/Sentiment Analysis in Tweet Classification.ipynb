{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('csv')\n",
    "\n",
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_csv('/Users/Ellina/Desktop/DS552/HW/HW5/ps5_tweets_text.csv', sep=',',error_bad_lines=False,encoding='utf-8')\n",
    "df_labels = pd.read_csv('ps5_tweets_labels.csv',sep=',',error_bad_lines=False,encoding='utf-8')\n",
    "df_numbers = pd.read_csv('ps5_tweets_labels_as_numbers.csv',sep=',',error_bad_lines=False,encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>37036</td>\n",
       "      <td>Minnesota classifies grocery store workers as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>37037</td>\n",
       "      <td>US Senator @ewarren has asked for information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>37038</td>\n",
       "      <td>Just commented on @thejournal_ie: Poll: Are yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>37039</td>\n",
       "      <td>My wife got laid off yesterday because the sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>37040</td>\n",
       "      <td>Humanity is doomed\\r\\r\\n#coronavirus #coronacr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                              Tweet\n",
       "0          0  https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...\n",
       "1          1  @mygovindia Today just after a week of lockdow...\n",
       "2          2  Tuskys partners with Amref to provide on groun...\n",
       "3          3  @chrissyteigen are u doing ur own grocery shop...\n",
       "4          4  UK Critical Care Nurse Cries at Empty SuperMar...\n",
       "...      ...                                                ...\n",
       "37036  37036  Minnesota classifies grocery store workers as ...\n",
       "37037  37037  US Senator @ewarren has asked for information ...\n",
       "37038  37038  Just commented on @thejournal_ie: Poll: Are yo...\n",
       "37039  37039  My wife got laid off yesterday because the sma...\n",
       "37040  37040  Humanity is doomed\\r\\r\\n#coronavirus #coronacr...\n",
       "\n",
       "[37041 rows x 2 columns]"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>37036</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>37037</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>37038</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>37039</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>37040</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id           Sentiment\n",
       "0          0  Extremely Positive\n",
       "1          1            Negative\n",
       "2          2             Neutral\n",
       "3          3            Negative\n",
       "4          4  Extremely Negative\n",
       "...      ...                 ...\n",
       "37036  37036            Negative\n",
       "37037  37037            Negative\n",
       "37038  37038  Extremely Negative\n",
       "37039  37039             Neutral\n",
       "37040  37040  Extremely Negative\n",
       "\n",
       "[37041 rows x 2 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>37036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>37037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>37038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>37039</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>37040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Label\n",
       "0          0      4\n",
       "1          1      1\n",
       "2          2      2\n",
       "3          3      1\n",
       "4          4      0\n",
       "...      ...    ...\n",
       "37036  37036      1\n",
       "37037  37037      1\n",
       "37038  37038      0\n",
       "37039  37039      2\n",
       "37040  37040      0\n",
       "\n",
       "[37041 rows x 2 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37041, 2)\n",
      "(37041, 2)\n",
      "(37041, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_text.shape)\n",
    "print(df_labels.shape)\n",
    "print(df_numbers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive              10282\n",
      "Negative               8930\n",
      "Neutral                6930\n",
      "Extremely Positive     5953\n",
      "Extremely Negative     4946\n",
      "Name: Sentiment, dtype: int64\n",
      "3    10282\n",
      "1     8930\n",
      "2     6930\n",
      "4     5953\n",
      "0     4946\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check some statistic \n",
    "print(df_labels['Sentiment'].value_counts())\n",
    "print(df_numbers['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>Minnesota classifies grocery store workers as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>US Senator @ewarren has asked for information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>Just commented on @thejournal_ie: Poll: Are yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>My wife got laid off yesterday because the sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>Humanity is doomed\\r\\r\\n#coronavirus #coronacr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet\n",
       "0      https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...\n",
       "1      @mygovindia Today just after a week of lockdow...\n",
       "2      Tuskys partners with Amref to provide on groun...\n",
       "3      @chrissyteigen are u doing ur own grocery shop...\n",
       "4      UK Critical Care Nurse Cries at Empty SuperMar...\n",
       "...                                                  ...\n",
       "37036  Minnesota classifies grocery store workers as ...\n",
       "37037  US Senator @ewarren has asked for information ...\n",
       "37038  Just commented on @thejournal_ie: Poll: Are yo...\n",
       "37039  My wife got laid off yesterday because the sma...\n",
       "37040  Humanity is doomed\\r\\r\\n#coronavirus #coronacr...\n",
       "\n",
       "[37041 rows x 1 columns]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = df_text[['Tweet']]\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentiment\n",
       "0      Extremely Positive\n",
       "1                Negative\n",
       "2                 Neutral\n",
       "3                Negative\n",
       "4      Extremely Negative\n",
       "...                   ...\n",
       "37036            Negative\n",
       "37037            Negative\n",
       "37038  Extremely Negative\n",
       "37039             Neutral\n",
       "37040  Extremely Negative\n",
       "\n",
       "[37041 rows x 1 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df_labels[['Sentiment']]\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "0          4\n",
       "1          1\n",
       "2          2\n",
       "3          1\n",
       "4          0\n",
       "...      ...\n",
       "37036      1\n",
       "37037      1\n",
       "37038      0\n",
       "37039      2\n",
       "37040      0\n",
       "\n",
       "[37041 rows x 1 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers = df_numbers[['Label']]\n",
    "df_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>Minnesota classifies grocery store workers as ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>US Senator @ewarren has asked for information ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>Just commented on @thejournal_ie: Poll: Are yo...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>My wife got laid off yesterday because the sma...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>Humanity is doomed\\r\\r\\n#coronavirus #coronacr...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet           Sentiment  \\\n",
       "0      https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...  Extremely Positive   \n",
       "1      @mygovindia Today just after a week of lockdow...            Negative   \n",
       "2      Tuskys partners with Amref to provide on groun...             Neutral   \n",
       "3      @chrissyteigen are u doing ur own grocery shop...            Negative   \n",
       "4      UK Critical Care Nurse Cries at Empty SuperMar...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "37036  Minnesota classifies grocery store workers as ...            Negative   \n",
       "37037  US Senator @ewarren has asked for information ...            Negative   \n",
       "37038  Just commented on @thejournal_ie: Poll: Are yo...  Extremely Negative   \n",
       "37039  My wife got laid off yesterday because the sma...             Neutral   \n",
       "37040  Humanity is doomed\\r\\r\\n#coronavirus #coronacr...  Extremely Negative   \n",
       "\n",
       "       Label  \n",
       "0          4  \n",
       "1          1  \n",
       "2          2  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "37036      1  \n",
       "37037      1  \n",
       "37038      0  \n",
       "37039      2  \n",
       "37040      0  \n",
       "\n",
       "[37041 rows x 3 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_text, df_labels, df_numbers], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tweets in each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Reference: https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/02.%20Exploratory%20Data%20Analysis/02.%20Exploratory%20Data%20Analysis.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a719c7ee542c4864b910b25c22a5cd61\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a719c7ee542c4864b910b25c22a5cd61\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a719c7ee542c4864b910b25c22a5cd61\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"size\": 50}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"tooltip\": [{\"type\": \"quantitative\", \"aggregate\": \"count\", \"title\": \"Number of Tweets\"}, {\"type\": \"nominal\", \"field\": \"Sentiment\"}], \"x\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\", \"axis\": {\"title\": \"Number of Tweets\"}}}, \"selection\": {\"selector019\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\"}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"text\": {\"type\": \"quantitative\", \"aggregate\": \"count\"}, \"tooltip\": [{\"type\": \"quantitative\", \"aggregate\": \"count\", \"title\": \"Number of Tweets\"}, {\"type\": \"nominal\", \"field\": \"Sentiment\"}], \"x\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\", \"axis\": {\"title\": \"Number of Tweets\"}}}}], \"data\": {\"url\": \"altair-data-903b327268c996f876a7ceb40391dd4c.csv\", \"format\": {\"type\": \"csv\"}}, \"height\": 300, \"title\": \"Number of Tweets in each sentiment\", \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars = alt.Chart(df).mark_bar(size=50).encode(\n",
    "    x=alt.X(\"Sentiment\"),\n",
    "    y=alt.Y(\"count():Q\", axis=alt.Axis(title='Number of Tweets')),\n",
    "    tooltip=[alt.Tooltip('count()', title='Number of Tweets'), 'Sentiment'],\n",
    "    color='Sentiment'\n",
    "\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    ").encode(\n",
    "    text='count()'\n",
    ")\n",
    "\n",
    "(bars + text).interactive().properties(\n",
    "    height=300, \n",
    "    width=700,\n",
    "    title = \"Number of Tweets in each sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of tweets in each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-fa859ef6cd284a7b8e6387d603790640\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fa859ef6cd284a7b8e6387d603790640\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fa859ef6cd284a7b8e6387d603790640\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"size\": 50}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"x\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"format\": \".0%\", \"title\": \"% of Tweets\"}, \"field\": \"PercentOfTotal\"}}, \"selection\": {\"selector020\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"transform\": [{\"window\": [{\"op\": \"sum\", \"field\": \"id\", \"as\": \"TotalArticles\"}], \"frame\": [null, null]}, {\"calculate\": \"datum.id / datum.TotalArticles\", \"as\": \"PercentOfTotal\"}]}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\"}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"text\": {\"type\": \"quantitative\", \"field\": \"PercentOfTotal\", \"format\": \".1%\"}, \"x\": {\"type\": \"nominal\", \"field\": \"Sentiment\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"format\": \".0%\", \"title\": \"% of Tweets\"}, \"field\": \"PercentOfTotal\"}}, \"transform\": [{\"window\": [{\"op\": \"sum\", \"field\": \"id\", \"as\": \"TotalArticles\"}], \"frame\": [null, null]}, {\"calculate\": \"datum.id / datum.TotalArticles\", \"as\": \"PercentOfTotal\"}]}], \"data\": {\"url\": \"altair-data-bb20a6cfcd038f72a372517b1fbdb559.csv\", \"format\": {\"type\": \"csv\"}}, \"height\": 300, \"title\": \"% of tweets in each sentiment\", \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'] = 1\n",
    "df2 = pd.DataFrame(df.groupby('Sentiment').count()['id']).reset_index()\n",
    "\n",
    "bars = alt.Chart(df2).mark_bar(size=50).encode(\n",
    "    x=alt.X('Sentiment'),\n",
    "    y=alt.Y('PercentOfTotal:Q', axis=alt.Axis(format='.0%', title='% of Tweets')),\n",
    "    color='Sentiment'\n",
    ").transform_window(\n",
    "    TotalArticles='sum(id)',\n",
    "    frame=[None, None]\n",
    ").transform_calculate(\n",
    "    PercentOfTotal=\"datum.id / datum.TotalArticles\"\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    #dx=5  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text=alt.Text('PercentOfTotal:Q', format='.1%')\n",
    ")\n",
    "\n",
    "(bars + text).interactive().properties(\n",
    "    height=300, \n",
    "    width=700,\n",
    "    title = \"% of tweets in each sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.Remove special character, URL, retweet\n",
    "- 2.Lowercase\n",
    "- 3.Puncation Signs\n",
    "- 4.Possessive Pronouns \n",
    "- 5.Optional : Try Lemmatizer (WordNet Lemmatizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Ellina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Ellina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "#Reference: https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/03.%20Feature%20Engineering/03.%20Feature%20Engineering.ipynb\n",
    "#Reference: https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@ymxr6 Makes my heart ache its the elderly tha...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COVID-19 wrecks aluminium prices and input cos...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>February Home Prices Increased by 4.1 Percent ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Want advice on avoiding scams related to #COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@dailyecho @BBCWatchdog @BBCNews @dailymail an...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           Sentiment  \\\n",
       "0  https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...  Extremely Positive   \n",
       "1  @mygovindia Today just after a week of lockdow...            Negative   \n",
       "2  Tuskys partners with Amref to provide on groun...             Neutral   \n",
       "3  @chrissyteigen are u doing ur own grocery shop...            Negative   \n",
       "4  UK Critical Care Nurse Cries at Empty SuperMar...  Extremely Negative   \n",
       "5  @ymxr6 Makes my heart ache its the elderly tha...  Extremely Negative   \n",
       "6  COVID-19 wrecks aluminium prices and input cos...             Neutral   \n",
       "7  February Home Prices Increased by 4.1 Percent ...            Positive   \n",
       "8  Want advice on avoiding scams related to #COVI...  Extremely Negative   \n",
       "9  @dailyecho @BBCWatchdog @BBCNews @dailymail an...            Negative   \n",
       "\n",
       "   Label  id  \n",
       "0      4   1  \n",
       "1      1   1  \n",
       "2      2   1  \n",
       "3      1   1  \n",
       "4      0   1  \n",
       "5      0   1  \n",
       "6      2   1  \n",
       "7      3   1  \n",
       "8      0   1  \n",
       "9      1   1  "
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Remove special character, URL, retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Gaisss! Please read this,and please limit ...\n",
       "1      Today just after a week of lockdown lot of c...\n",
       "2    Tuskys partners with Amref to provide on groun...\n",
       "3      are u doing ur own grocery shopping now like...\n",
       "4    UK Critical Care Nurse Cries at Empty SuperMar...\n",
       "Name: Tweet_change_1, dtype: object"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 Remove special character, URL, retweet\n",
    "df['Tweet_change_1'] = df['Tweet'].str.replace(\"\\r\", \" \")\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace(\"\\n\", \" \")\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace(\"\\\\\", \" \")\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace(\"    \", \" \")\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace(\"''\",\"\")\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace('http\\S+', \" \") #Remove URL\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace('@\\S+', \" \") #Remove retweet\n",
    "df['Tweet_change_1'] = df['Tweet_change_1'].str.replace('#\\S+', \" \") #Remove retweet\n",
    "\n",
    "\n",
    "df['Tweet_change_1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gaisss! please read this,and please limit ...\n",
       "1      today just after a week of lockdown lot of c...\n",
       "2    tuskys partners with amref to provide on groun...\n",
       "3      are u doing ur own grocery shopping now like...\n",
       "4    uk critical care nurse cries at empty supermar...\n",
       "Name: Tweet_change_2, dtype: object"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2 Lowercase \n",
    "df['Tweet_change_2'] = df['Tweet_change_1'].str.lower()\n",
    "\n",
    "df['Tweet_change_2'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Puncation Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Puncation signs\n",
    "\n",
    "df['Tweet_change_3'] = df['Tweet_change_2'].str.replace(\"?\", \" \")\n",
    "\n",
    "df['Tweet_change_3'] = df['Tweet_change_2']\n",
    "\n",
    "punctuation_signs = list(\"?.:!,;@#\\//\\|-\\)\\(\\}\\{\\[\\]\\\"$\")\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Tweet_change_3'] = df['Tweet_change_3'].str.replace(punct_sign, \" \")\n",
    "    df['Tweet_change_3'] = df['Tweet_change_3'].str.replace(punct_sign, \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gaisss  please read this and please limit ...\n",
       "1      today just after a week of lockdown lot of c...\n",
       "2    tuskys partners with amref to provide on groun...\n",
       "3      are u doing ur own grocery shopping now like...\n",
       "4    uk critical care nurse cries at empty supermar...\n",
       "Name: Tweet_change_3, dtype: object"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_change_3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Possessive Pronouns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gaisss  please read this and please limit ...\n",
       "1      today just after a week of lockdown lot of c...\n",
       "2    tuskys partners with amref to provide on groun...\n",
       "3      are u doing ur own grocery shopping now like...\n",
       "4    uk critical care nurse cries at empty supermar...\n",
       "Name: Tweet_change_4, dtype: object"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 Possessive Pronouns \n",
    "df['Tweet_change_4'] = df['Tweet_change_3'].str.replace(\"'s'\", \" \")\n",
    "\n",
    "df['Tweet_change_4'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Ellina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gaisss  please read this and please limit ...\n",
       "1      today just after a week of lockdown lot of c...\n",
       "2    tuskys partners with amref to provide on groun...\n",
       "3      are u doing ur own grocery shopping now like...\n",
       "4    uk critical care nurse cries at empty supermar...\n",
       "Name: Tweet_change_5, dtype: object"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.5 Stopwords\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Tweet_change_5'] = df['Tweet_change_4'].str.replace(regex_stopword, \" \")\n",
    "\n",
    "df['Tweet_change_5'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Ellina/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://www.cnblogs.com/jclian91/p/9898511.html\n",
    "# 2.5 Lemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "re_list_train = []\n",
    "aaa = []\n",
    "\n",
    "for sentence in df['Tweet_change_5']:\n",
    "    lemmatized_text_list = []\n",
    "    tokens = word_tokenize(sentence)   \n",
    "    tagged_sent = pos_tag(tokens)     \n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmatized_text_list.append(wnl.lemmatize(tag[0], pos=wordnet_pos)) \n",
    "        \n",
    "    re_string = \"\"\n",
    "    aaa += lemmatized_text_list\n",
    "    for i in lemmatized_text_list:\n",
    "        re_string = re_string + i + \" \"\n",
    "    re_list_train.append(re_string)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        gaisss please read this and please limit yours...\n",
       "1        today just after a week of lockdown lot of con...\n",
       "2        tuskys partner with amref to provide on ground...\n",
       "3        be u do ur own grocery shopping now like a reg...\n",
       "4        uk critical care nurse cry at empty supermarke...\n",
       "                               ...                        \n",
       "37036    minnesota classifies grocery store worker a em...\n",
       "37037    u senator have ask for information about a the...\n",
       "37038    just comment on poll be you do more online sho...\n",
       "37039    my wife get lay off yesterday because the smal...\n",
       "37040                                    humanity be doom \n",
       "Name: Tweet_change_6, Length: 37041, dtype: object"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_change_6'] = re_list_train\n",
    "df['Tweet_change_6'].head()\n",
    "df['Tweet_change_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = [i for i in text.split(' ') if (len(i)>1) and i not in stopwords]\n",
    "    result = [lemmatizer.lemmatize(i) for i in result]\n",
    "    words_count.update(result)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet_change_1</th>\n",
       "      <th>Tweet_change_2</th>\n",
       "      <th>Tweet_change_3</th>\n",
       "      <th>Tweet_change_4</th>\n",
       "      <th>Tweet_change_5</th>\n",
       "      <th>Tweet_change_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gaisss! Please read this,and please limit ...</td>\n",
       "      <td>gaisss! please read this,and please limit ...</td>\n",
       "      <td>gaisss  please read this and please limit ...</td>\n",
       "      <td>gaisss  please read this and please limit ...</td>\n",
       "      <td>gaisss  please read this and please limit ...</td>\n",
       "      <td>gaisss please read this and please limit yours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mygovindia Today just after a week of lockdow...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Today just after a week of lockdown lot of c...</td>\n",
       "      <td>today just after a week of lockdown lot of c...</td>\n",
       "      <td>today just after a week of lockdown lot of c...</td>\n",
       "      <td>today just after a week of lockdown lot of c...</td>\n",
       "      <td>today just after a week of lockdown lot of c...</td>\n",
       "      <td>today just after a week of lockdown lot of con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuskys partners with Amref to provide on groun...</td>\n",
       "      <td>tuskys partners with amref to provide on groun...</td>\n",
       "      <td>tuskys partners with amref to provide on groun...</td>\n",
       "      <td>tuskys partners with amref to provide on groun...</td>\n",
       "      <td>tuskys partners with amref to provide on groun...</td>\n",
       "      <td>tuskys partner with amref to provide on ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chrissyteigen are u doing ur own grocery shop...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>are u doing ur own grocery shopping now like...</td>\n",
       "      <td>are u doing ur own grocery shopping now like...</td>\n",
       "      <td>are u doing ur own grocery shopping now like...</td>\n",
       "      <td>are u doing ur own grocery shopping now like...</td>\n",
       "      <td>are u doing ur own grocery shopping now like...</td>\n",
       "      <td>be u do ur own grocery shopping now like a reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UK Critical Care Nurse Cries at Empty SuperMar...</td>\n",
       "      <td>uk critical care nurse cries at empty supermar...</td>\n",
       "      <td>uk critical care nurse cries at empty supermar...</td>\n",
       "      <td>uk critical care nurse cries at empty supermar...</td>\n",
       "      <td>uk critical care nurse cries at empty supermar...</td>\n",
       "      <td>uk critical care nurse cry at empty supermarke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>Minnesota classifies grocery store workers as ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota classifies grocery store workers as ...</td>\n",
       "      <td>minnesota classifies grocery store workers as ...</td>\n",
       "      <td>minnesota classifies grocery store workers as ...</td>\n",
       "      <td>minnesota classifies grocery store workers as ...</td>\n",
       "      <td>minnesota classifies grocery store workers as ...</td>\n",
       "      <td>minnesota classifies grocery store worker a em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>US Senator @ewarren has asked for information ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US Senator   has asked for information about  ...</td>\n",
       "      <td>us senator   has asked for information about  ...</td>\n",
       "      <td>us senator   has asked for information about  ...</td>\n",
       "      <td>us senator   has asked for information about  ...</td>\n",
       "      <td>us senator   has asked for information about  ...</td>\n",
       "      <td>u senator have ask for information about a the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>Just commented on @thejournal_ie: Poll: Are yo...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Just commented on   Poll: Are you doing more o...</td>\n",
       "      <td>just commented on   poll: are you doing more o...</td>\n",
       "      <td>just commented on   poll  are you doing more o...</td>\n",
       "      <td>just commented on   poll  are you doing more o...</td>\n",
       "      <td>just commented on   poll  are you doing more o...</td>\n",
       "      <td>just comment on poll be you do more online sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>My wife got laid off yesterday because the sma...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife got laid off yesterday because the sma...</td>\n",
       "      <td>my wife got laid off yesterday because the sma...</td>\n",
       "      <td>my wife got laid off yesterday because the sma...</td>\n",
       "      <td>my wife got laid off yesterday because the sma...</td>\n",
       "      <td>my wife got laid off yesterday because the sma...</td>\n",
       "      <td>my wife get lay off yesterday because the smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>Humanity is doomed\\r\\r\\n#coronavirus #coronacr...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Humanity is doomed</td>\n",
       "      <td>humanity is doomed</td>\n",
       "      <td>humanity is doomed</td>\n",
       "      <td>humanity is doomed</td>\n",
       "      <td>humanity is doomed</td>\n",
       "      <td>humanity be doom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet           Sentiment  \\\n",
       "0      https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Ple...  Extremely Positive   \n",
       "1      @mygovindia Today just after a week of lockdow...            Negative   \n",
       "2      Tuskys partners with Amref to provide on groun...             Neutral   \n",
       "3      @chrissyteigen are u doing ur own grocery shop...            Negative   \n",
       "4      UK Critical Care Nurse Cries at Empty SuperMar...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "37036  Minnesota classifies grocery store workers as ...            Negative   \n",
       "37037  US Senator @ewarren has asked for information ...            Negative   \n",
       "37038  Just commented on @thejournal_ie: Poll: Are yo...  Extremely Negative   \n",
       "37039  My wife got laid off yesterday because the sma...             Neutral   \n",
       "37040  Humanity is doomed\\r\\r\\n#coronavirus #coronacr...  Extremely Negative   \n",
       "\n",
       "       Label  id                                     Tweet_change_1  \\\n",
       "0          4   1      Gaisss! Please read this,and please limit ...   \n",
       "1          1   1    Today just after a week of lockdown lot of c...   \n",
       "2          2   1  Tuskys partners with Amref to provide on groun...   \n",
       "3          1   1    are u doing ur own grocery shopping now like...   \n",
       "4          0   1  UK Critical Care Nurse Cries at Empty SuperMar...   \n",
       "...      ...  ..                                                ...   \n",
       "37036      1   1  Minnesota classifies grocery store workers as ...   \n",
       "37037      1   1  US Senator   has asked for information about  ...   \n",
       "37038      0   1  Just commented on   Poll: Are you doing more o...   \n",
       "37039      2   1  My wife got laid off yesterday because the sma...   \n",
       "37040      0   1                 Humanity is doomed                   \n",
       "\n",
       "                                          Tweet_change_2  \\\n",
       "0          gaisss! please read this,and please limit ...   \n",
       "1        today just after a week of lockdown lot of c...   \n",
       "2      tuskys partners with amref to provide on groun...   \n",
       "3        are u doing ur own grocery shopping now like...   \n",
       "4      uk critical care nurse cries at empty supermar...   \n",
       "...                                                  ...   \n",
       "37036  minnesota classifies grocery store workers as ...   \n",
       "37037  us senator   has asked for information about  ...   \n",
       "37038  just commented on   poll: are you doing more o...   \n",
       "37039  my wife got laid off yesterday because the sma...   \n",
       "37040                 humanity is doomed                   \n",
       "\n",
       "                                          Tweet_change_3  \\\n",
       "0          gaisss  please read this and please limit ...   \n",
       "1        today just after a week of lockdown lot of c...   \n",
       "2      tuskys partners with amref to provide on groun...   \n",
       "3        are u doing ur own grocery shopping now like...   \n",
       "4      uk critical care nurse cries at empty supermar...   \n",
       "...                                                  ...   \n",
       "37036  minnesota classifies grocery store workers as ...   \n",
       "37037  us senator   has asked for information about  ...   \n",
       "37038  just commented on   poll  are you doing more o...   \n",
       "37039  my wife got laid off yesterday because the sma...   \n",
       "37040                 humanity is doomed                   \n",
       "\n",
       "                                          Tweet_change_4  \\\n",
       "0          gaisss  please read this and please limit ...   \n",
       "1        today just after a week of lockdown lot of c...   \n",
       "2      tuskys partners with amref to provide on groun...   \n",
       "3        are u doing ur own grocery shopping now like...   \n",
       "4      uk critical care nurse cries at empty supermar...   \n",
       "...                                                  ...   \n",
       "37036  minnesota classifies grocery store workers as ...   \n",
       "37037  us senator   has asked for information about  ...   \n",
       "37038  just commented on   poll  are you doing more o...   \n",
       "37039  my wife got laid off yesterday because the sma...   \n",
       "37040                 humanity is doomed                   \n",
       "\n",
       "                                          Tweet_change_5  \\\n",
       "0          gaisss  please read this and please limit ...   \n",
       "1        today just after a week of lockdown lot of c...   \n",
       "2      tuskys partners with amref to provide on groun...   \n",
       "3        are u doing ur own grocery shopping now like...   \n",
       "4      uk critical care nurse cries at empty supermar...   \n",
       "...                                                  ...   \n",
       "37036  minnesota classifies grocery store workers as ...   \n",
       "37037  us senator   has asked for information about  ...   \n",
       "37038  just commented on   poll  are you doing more o...   \n",
       "37039  my wife got laid off yesterday because the sma...   \n",
       "37040                 humanity is doomed                   \n",
       "\n",
       "                                          Tweet_change_6  \n",
       "0      gaisss please read this and please limit yours...  \n",
       "1      today just after a week of lockdown lot of con...  \n",
       "2      tuskys partner with amref to provide on ground...  \n",
       "3      be u do ur own grocery shopping now like a reg...  \n",
       "4      uk critical care nurse cry at empty supermarke...  \n",
       "...                                                  ...  \n",
       "37036  minnesota classifies grocery store worker a em...  \n",
       "37037  u senator have ask for information about a the...  \n",
       "37038  just comment on poll be you do more online sho...  \n",
       "37039  my wife get lay off yesterday because the smal...  \n",
       "37040                                  humanity be doom   \n",
       "\n",
       "[37041 rows x 10 columns]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Tweet_change_6','Label']\n",
    "df = df[selected_columns]\n",
    "df = df.rename(columns={'Tweet_change_6':'Tweet_Clean'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Clean</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaisss please read this and please limit yours...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today just after a week of lockdown lot of con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tuskys partner with amref to provide on ground...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be u do ur own grocery shopping now like a reg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uk critical care nurse cry at empty supermarke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37036</th>\n",
       "      <td>minnesota classifies grocery store worker a em...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37037</th>\n",
       "      <td>u senator have ask for information about a the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37038</th>\n",
       "      <td>just comment on poll be you do more online sho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>my wife get lay off yesterday because the smal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37040</th>\n",
       "      <td>humanity be doom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Tweet_Clean  Label\n",
       "0      gaisss please read this and please limit yours...      4\n",
       "1      today just after a week of lockdown lot of con...      1\n",
       "2      tuskys partner with amref to provide on ground...      2\n",
       "3      be u do ur own grocery shopping now like a reg...      1\n",
       "4      uk critical care nurse cry at empty supermarke...      0\n",
       "...                                                  ...    ...\n",
       "37036  minnesota classifies grocery store worker a em...      1\n",
       "37037  u senator have ask for information about a the...      1\n",
       "37038  just comment on poll be you do more online sho...      0\n",
       "37039  my wife get lay off yesterday because the smal...      2\n",
       "37040                                  humanity be doom       0\n",
       "\n",
       "[37041 rows x 2 columns]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split Train + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29632,) (29632,)\n",
      "(7409,) (7409,)\n"
     ]
    }
   ],
   "source": [
    "y = df['Label']\n",
    "X = df['Tweet_Clean']\n",
    "\n",
    "#Split Training & Testing Set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Split Training Set again into Training & Validation Set\n",
    "#Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "print(Xtrain.shape, ytrain.shape)\n",
    "#print(Xval.shape, yval.shape)\n",
    "print(Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Word Embedding + CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Word Embedding with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer(num_words = 10000, split=\" \")\n",
    "\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(Xtrain)\n",
    "\n",
    "# texts_to_sequences (convert text to sequence)\n",
    "seq_Xtrain = tokenizer.texts_to_sequences(Xtrain)\n",
    "seq_Xtest = tokenizer.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24859 different vocabularies in total after tokenization\n"
     ]
    }
   ],
   "source": [
    "vocab_count = len(tokenizer.word_index) + 1\n",
    "print(\"There are %d different vocabularies in total after tokenization\"%vocab_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximun length of comment has 66 words\n"
     ]
    }
   ],
   "source": [
    "# Maximun words\n",
    "max_length = max([len(str(s).split()) for s in Xtrain])\n",
    "print('The maximun length of comment has %d words'%max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad sequence of Xtrain: (29632, 66)\n",
      "pad sequence of Xtest: (7409, 66)\n"
     ]
    }
   ],
   "source": [
    "#pad sequences\n",
    "pad_Xtrain = pad_sequences(seq_Xtrain, maxlen=max_length, padding='post')\n",
    "pad_Xtest = pad_sequences(seq_Xtest, maxlen=max_length, padding='post')\n",
    "\n",
    "print('pad sequence of Xtrain:', pad_Xtrain.shape)\n",
    "print('pad sequence of Xtest:',pad_Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
    "# define model\n",
    "model = Sequential([])\n",
    "model.add(Embedding(vocab_count, 100, input_length=max_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 66, 100)           2485900   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 59, 32)            25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                9290      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 2,520,877\n",
      "Trainable params: 2,520,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 CNN compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# compile network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "741/741 [==============================] - 45s 59ms/step - loss: 1.3881 - accuracy: 0.3858 - val_loss: 0.8127 - val_accuracy: 0.6853\n",
      "Epoch 2/5\n",
      "741/741 [==============================] - 43s 58ms/step - loss: 0.6498 - accuracy: 0.7657 - val_loss: 0.7053 - val_accuracy: 0.7388\n",
      "Epoch 3/5\n",
      "741/741 [==============================] - 41s 56ms/step - loss: 0.4549 - accuracy: 0.8481 - val_loss: 0.7165 - val_accuracy: 0.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a796220>"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(pad_Xtrain, ytrain, epochs=5, validation_split=0.2, batch_size=32, callbacks=[early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of CNN is 0.736\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(pad_Xtest, ytest, verbose=0)\n",
    "print('The accuracy of CNN is %.3f'%(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bag-of-words method with MultiNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37041x7121 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 838992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "count_v = CountVectorizer(min_df = 5, binary = True)\n",
    "word_count_matrix = count_v.fit_transform(df['Tweet_Clean'])\n",
    "word_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = word_count_matrix.toarray().sum(axis=0)\n",
    "word_list = count_v.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.11308844, 5.51839281, 9.72804821, ..., 8.18760317, 9.72804821,\n",
       "       8.26171114])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF (convert text to matrix)\n",
    "tf_idf = TfidfTransformer()\n",
    "tf_idf.fit(word_count_matrix)\n",
    "tf_idf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7121,)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.idf_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37041x7121 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 838992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector = tf_idf.transform(word_count_matrix)\n",
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vector', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('mulNB', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vector', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('mulNB', MultinomialNB())])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3866918612498313"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 GridSearchCV + Multi-NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 308.779s\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://www.kaggle.com/tonypeng1/tf-idf-with-multinomial-nb-and-cross-validation/comments\n",
    "#Using GridSearchCV\n",
    "from time import time\n",
    "parameters = {\n",
    "    'mulNB__alpha': [1, 0.7, 0.4, 0.2, 0.1, 0.09, 0.08, 0.07, 0.06, 0.03, 0.01] \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=10, refit=True)\n",
    "t0 = time()\n",
    "grid.fit(Xtrain, ytrain)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44556585881745303\n",
      "{'mulNB__alpha': 0.06}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of MultiNB with TF-IDF is 0.457\n"
     ]
    }
   ],
   "source": [
    "score = grid.score(Xtest, ytest)\n",
    "print('The accuracy of MultiNB with TF-IDF is %.03f'%(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
